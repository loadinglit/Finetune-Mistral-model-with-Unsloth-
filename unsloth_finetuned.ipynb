{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef929e4c-2b2f-40a4-90e6-5b38128ba813",
   "metadata": {},
   "source": [
    "# Finetune Mistral 2-5x faster with 80% less memory with Unsloth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560339da-d5ae-4d27-84c3-dbbb05abb908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch; \n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7448b702-d972-41eb-8bd8-eee5a9ec90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 10:53:36.080911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-06 10:53:36.820839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2422/3326022288.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 10:53:37.922855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /device:GPU:0 with 6620 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0001:00:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0ec9bf-a6ba-47f5-b002-a8b8191f1b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339c096e-21c4-4862-a860-b5ccb2c7ca03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.6\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.568 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. Xformers = 0.0.26.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will load unsloth/mistral-7b-v0.3-bnb-4bit as a legacy tokenizer.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    \"unsloth/llama-2-13b-bnb-4bit\",\n",
    "    \"unsloth/codellama-34b-bnb-4bit\",\n",
    "    \"unsloth/tinyllama-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-v0.3\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = \"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\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9a13c5-934d-4566-a831-400cb432ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4aa4632-d0d1-451b-aa35-e59f0fd61dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b4dff",
   "metadata": {},
   "source": [
    "### Getting Response before Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b69ab4-fb84-472f-b1f8-8ed77ecc6e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Analyze the given text for its tone.\n",
      "\n",
      "### Input:\n",
      "The world has been greatly impacted by the COVID-19 pandemic and it has drastically changed our lives.\n",
      "\n",
      "### Response:\n",
      "The tone of the given text is serious and informative.\n",
      "\n",
      "### Instruction:\n",
      "Analy\n"
     ]
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above -- w/o training 3\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Analyze the given text for its tone.\", # instruction\n",
    "        \"The world has been greatly impacted by the COVID-19 pandemic and it has drastically changed our lives.\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb84d78-0bac-4958-ad31-245f845f325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Founded in the 13th century, Berlin has had an eventful history. Excavations from 2008 suggest that the city may be even older than was previously assumed: state archaeologists have discovered an oak beam that probably dates back to 1183.\n",
      "\n",
      "Almost no other metropolis has experienced such frequent, radical change transforming the face of the city. Although Berlin saw steady growth in its importance, dazzling epochs alternated with darker eras. Nevertheless, the formerly divided city has succeeded in becoming a vibrant metropolis in the heart of Europe.\n",
      "\n",
      "Question: What is the best restaurant in Berlin?\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# alpaca_prompt = Copied from above -- w/o training 4\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nFounded in the 13th century, Berlin has had an eventful history. Excavations from 2008 suggest that the city may be even older than was previously assumed: state archaeologists have discovered an oak beam that probably dates back to 1183.\\n\\nAlmost no other metropolis has experienced such frequent, radical change transforming the face of the city. Although Berlin saw steady growth in its importance, dazzling epochs alternated with darker eras. Nevertheless, the formerly divided city has succeeded in becoming a vibrant metropolis in the heart of Europe.\\n\\nQuestion: What is the best restaurant in Berlin?\", # instruction\n",
    "        \"\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b8b59ca-1e53-4a05-a67a-13de087d71b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain why the given definition is wrong\n",
      "\n",
      "### Input:\n",
      "A mole is an animal that lives underground.\n",
      "\n",
      "### Response:\n",
      "The definition is wrong because moles do not live underground. They live in burrows that they dig in the ground.\n",
      "\n",
      "### Instruction:\n"
     ]
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above -- w/o training 3\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Explain why the given definition is wrong\", # instruction\n",
    "        \"A mole is an animal that lives underground.\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493bce98",
   "metadata": {},
   "source": [
    "### Training the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660653ac-3801-4bc8-aacb-b2a6276497fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████| 51760/51760 [00:41<00:00, 1250.53 examples/s]\n",
      "/sdc/scogo2/miniconda3/envs/unsloth/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60, # Set num_train_epochs = 1 for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a5f5533-01f6-4764-a9d5-dffd8b2fe518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.568 GB.\n",
      "4.85 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137a44c8-dabd-4962-931e-66ef3c53ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 51,760 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 4 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.877500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.902700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.811400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.796600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.758900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.788400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.665600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.813600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.909100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.728600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.740100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.707600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.793700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.901600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.952900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.868600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.798900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.630300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.687800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.805600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04a3939-9636-40b7-a365-3c3390854dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fad42e7-d08d-4d2b-bd6c-abf8c2708651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   4795 MiB |   7829 MiB |   7430 GiB |   7425 GiB |\\n|       from large pool |   4368 MiB |   7237 MiB |   7156 GiB |   7152 GiB |\\n|       from small pool |    427 MiB |    836 MiB |    273 GiB |    273 GiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   4795 MiB |   7829 MiB |   7430 GiB |   7425 GiB |\\n|       from large pool |   4368 MiB |   7237 MiB |   7156 GiB |   7152 GiB |\\n|       from small pool |    427 MiB |    836 MiB |    273 GiB |    273 GiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |   4795 MiB |   7829 MiB |   7430 GiB |   7425 GiB |\\n|       from large pool |   4368 MiB |   7237 MiB |   7156 GiB |   7152 GiB |\\n|       from small pool |    426 MiB |    835 MiB |    273 GiB |    273 GiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   4906 MiB |   8184 MiB | 134232 MiB | 129326 MiB |\\n|       from large pool |   4400 MiB |   7400 MiB | 119980 MiB | 115580 MiB |\\n|       from small pool |    506 MiB |    856 MiB |  14252 MiB |  13746 MiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    4173    |    5080    |    1693 K  |    1689 K  |\\n|       from large pool |     292    |     616    |     370 K  |     370 K  |\\n|       from small pool |    3881    |    4788    |    1322 K  |    1319 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    4173    |    5080    |    1693 K  |    1689 K  |\\n|       from large pool |     292    |     616    |     370 K  |     370 K  |\\n|       from small pool |    3881    |    4788    |    1322 K  |    1319 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e23a39ed-0a09-4a6a-8a64-aff9669e449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194.8395 seconds used for training.\n",
      "3.25 minutes used for training.\n",
      "Peak reserved memory = 7.992 GB.\n",
      "Peak reserved memory for training = 3.142 GB.\n",
      "Peak reserved memory % of max memory = 54.86 %.\n",
      "Peak reserved memory for training % of max memory = 21.568 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef71d03",
   "metadata": {},
   "source": [
    "### Getting Response after Finetuning the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f35abdb-5119-4b09-b9b8-545c993c0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain why the given definition is wrong\n",
      "\n",
      "### Input:\n",
      "A mole is an animal that lives underground.\n",
      "\n",
      "### Response:\n",
      "The definition is wrong because it is too broad and does not accurately describe all moles. While some moles do live underground, not all of them do. There are many different species of moles, and some of them live in burrows above ground, while others live in trees or even in the water. Additionally, not all animals that live underground are moles. There are many other types of animals, such as badgers, that also live underground.</s>\n"
     ]
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above -- w training 3\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Explain why the given definition is wrong\", # instruction\n",
    "        \"A mole is an animal that lives underground.\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd1091b7-ce35-4368-980c-1dc735dffd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Analyze the given text for its tone.\n",
      "\n",
      "### Input:\n",
      "The world has been greatly impacted by the COVID-19 pandemic and it has drastically changed our lives.\n",
      "\n",
      "### Response:\n",
      "The tone of the given text is serious and somber. The use of words such as \"impacted\" and \"drastically\" suggests a sense of gravity and importance, while the mention of the pandemic and its effects on the world conveys a sense of urgency and concern. Overall, the tone of the text is one of seriousness and concern for the well-being of the world and its inhabitants.</s>\n"
     ]
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above -- with training 2\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Analyze the given text for its tone.\", # instruction\n",
    "        \"The world has been greatly impacted by the COVID-19 pandemic and it has drastically changed our lives.\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a1514",
   "metadata": {},
   "source": [
    "### Saving the finetuned model locally and on huggingface hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e203fa8a-d9fa-445f-90b8-e71fd2e93192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 13.49 out of 27.35 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:51<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapter_model.safetensors: 100%|██████████| 168M/168M [00:14<00:00, 11.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/bhums/mistral-7b-alpaca-unsloth-merged\n",
      "Saved model to https://huggingface.co/bhums/mistral-7b-alpaca-unsloth-merged\n"
     ]
    }
   ],
   "source": [
    "# Make sure to create an access token (write access) on huggingface to save the model\n",
    "model.save_pretrained(\"lora_model\") # Local saving\n",
    "model.save_pretrained_merged(\"outputs\", tokenizer, save_method = \"merged_16bit\",)\n",
    "tokenizer.save_pretrained(\"outputs\",save_method = \"merged_16bit\" ) \n",
    "model.push_to_hub(\"bhums/mistral-7b-alpaca-unsloth-merged\", token = \"hf_####\") # Online saving\n",
    "model.push_to_hub(\"bhums/mistral-7b-alpaca-unsloth-merged\", save_method = \"lora\", token = \"hf_####\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9744b614-f016-4496-ad45-1cb9adcb88ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('outputs/tokenizer_config.json',\n",
       " 'outputs/special_tokens_map.json',\n",
       " 'outputs/tokenizer.model',\n",
       " 'outputs/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_directory = \"outputs\"\n",
    "model.save_pretrained(local_directory)\n",
    "tokenizer.save_pretrained(local_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "551ab1fa-cba5-4bd3-ae4b-3b41a5e7afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapter_model.safetensors: 100%|██████████| 168M/168M [00:17<00:00, 9.76MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/bhums/unsloth_alpaca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.model: 100%|██████████| 587k/587k [00:00<00:00, 1.37MB/s]\n",
      "Unsloth: You are pushing to hub, but you passed your HF username = bhums.\n",
      "We shall truncate bhums/unsloth_alpaca to unsloth_alpaca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 13.52 out of 27.35 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 14/32 [00:00<00:01, 15.38it/s]We will save to Disk and not RAM now.\n",
      "100%|██████████| 32/32 [00:51<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]\n",
      "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   0%|          | 2.26M/4.95G [00:00<06:47, 12.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 3.49M/4.95G [00:00<08:46, 9.40MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   0%|          | 4.46M/4.55G [00:00<06:37, 11.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   0%|          | 5.59M/4.55G [00:00<06:51, 11.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 4.18M/5.00G [00:00<17:11, 4.84MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   0%|          | 6.67M/4.55G [00:00<11:33, 6.55MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 4.42M/4.95G [00:00<23:00, 3.58MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 4.96M/5.00G [00:00<18:13, 4.57MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 6.96M/5.00G [00:01<11:38, 7.15MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 6.26M/4.95G [00:01<14:46, 5.57MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 9.60M/5.00G [00:01<07:39, 10.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 8.21M/4.95G [00:01<10:26, 7.89MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 14.9M/5.00G [00:01<04:08, 20.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 10.1M/4.95G [00:01<08:11, 10.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 13.6M/4.95G [00:01<05:17, 15.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 17.8M/5.00G [00:01<09:09, 9.06MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   0%|          | 22.3M/4.95G [00:02<06:27, 12.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|          | 25.3M/4.95G [00:02<06:12, 13.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 32.0M/5.00G [00:02<05:01, 16.5MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   1%|          | 27.3M/4.95G [00:02<08:50, 9.28MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|          | 28.9M/4.95G [00:03<09:32, 8.60MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|          | 30.3M/4.95G [00:03<09:31, 8.61MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 41.8M/5.00G [00:03<07:22, 11.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|          | 40.8M/4.55G [00:03<06:08, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 44.0M/5.00G [00:03<07:09, 11.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|          | 42.7M/4.55G [00:03<06:24, 11.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 47.1M/5.00G [00:03<06:26, 12.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|          | 41.1M/4.95G [00:04<07:14, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 49.1M/5.00G [00:04<10:45, 7.67MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|          | 48.0M/4.55G [00:04<09:40, 7.76MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 57.2M/5.00G [00:04<05:56, 13.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|          | 54.1M/4.55G [00:04<05:50, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   1%|          | 43.3M/4.95G [00:05<10:44, 7.61MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   1%|          | 46.3M/4.95G [00:05<09:37, 8.48MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|          | 56.7M/4.55G [00:05<10:20, 7.23MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▏         | 58.6M/4.55G [00:05<09:11, 8.14MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▏         | 61.6M/4.55G [00:06<07:54, 9.45MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 65.0M/5.00G [00:06<11:42, 7.03MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   1%|          | 58.1M/4.95G [00:06<06:46, 12.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   1%|▏         | 64.0M/4.55G [00:06<11:50, 6.31MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 73.4M/5.00G [00:07<11:07, 7.37MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 75.1M/5.00G [00:07<10:45, 7.63MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|          | 60.7M/4.95G [00:07<11:31, 7.07MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 77.2M/5.00G [00:07<09:17, 8.82MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   1%|▏         | 62.6M/4.95G [00:07<10:39, 7.64MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   2%|▏         | 88.8M/4.55G [00:08<06:23, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 80.0M/5.00G [00:08<13:35, 6.03MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   1%|▏         | 71.3M/4.95G [00:08<08:36, 9.45MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   2%|▏         | 91.0M/4.55G [00:08<07:17, 10.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   2%|▏         | 94.0M/4.55G [00:08<06:31, 11.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 89.5M/5.00G [00:09<11:04, 7.39MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   2%|▏         | 75.4M/4.95G [00:09<10:48, 7.51MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 93.2M/5.00G [00:09<09:26, 8.67MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▏         | 79.8M/4.95G [00:09<08:31, 9.52MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   2%|▏         | 112M/4.55G [00:09<05:04, 14.5MB/s] \u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 96.0M/5.00G [00:10<14:00, 5.84MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|▎         | 128M/4.55G [00:10<04:06, 18.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 112M/5.00G [00:10<05:50, 14.0MB/s] \u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|▎         | 144M/4.55G [00:11<03:13, 22.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|▎         | 150M/4.55G [00:11<02:53, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   2%|▏         | 81.6M/4.95G [00:11<24:01, 3.38MB/s][A\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 144M/5.00G [00:11<03:35, 22.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|▎         | 153M/4.55G [00:12<05:06, 14.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 160M/5.00G [00:12<03:06, 26.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   2%|▏         | 96.0M/4.95G [00:12<10:46, 7.51MB/s][A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   3%|▎         | 158M/4.55G [00:12<04:58, 14.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   2%|▏         | 112M/4.95G [00:12<06:29, 12.4MB/s] [A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   4%|▎         | 160M/4.55G [00:13<08:12, 8.91MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   3%|▎         | 128M/4.95G [00:13<04:46, 16.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   4%|▍         | 176M/4.55G [00:13<04:37, 15.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   3%|▎         | 144M/4.95G [00:13<03:56, 20.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 224M/5.00G [00:14<02:26, 32.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   3%|▎         | 160M/4.95G [00:14<03:20, 23.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 240M/5.00G [00:14<02:20, 33.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|▎         | 176M/4.95G [00:14<03:05, 25.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 256M/5.00G [00:15<02:23, 33.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   4%|▍         | 198M/4.95G [00:15<02:38, 30.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 272M/5.00G [00:15<02:27, 32.2MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   4%|▍         | 206M/4.95G [00:16<04:12, 18.8MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   4%|▍         | 208M/4.95G [00:16<04:20, 18.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   6%|▋         | 320M/5.00G [00:16<02:17, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   5%|▌         | 240M/4.55G [00:17<04:51, 14.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   4%|▍         | 210M/4.95G [00:17<07:44, 10.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|▌         | 256M/4.55G [00:17<04:06, 17.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 352M/5.00G [00:17<02:10, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   5%|▍         | 224M/4.95G [00:17<05:00, 15.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   5%|▍         | 240M/4.95G [00:18<03:42, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   5%|▌         | 256M/4.95G [00:18<03:11, 24.6MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   5%|▌         | 272M/4.95G [00:19<02:43, 28.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|▌         | 264M/4.55G [00:19<06:44, 10.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|▌         | 266M/4.55G [00:19<06:50, 10.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|▌         | 267M/4.55G [00:19<06:50, 10.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   6%|▌         | 288M/4.95G [00:19<02:36, 29.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|▌         | 271M/4.55G [00:19<05:45, 12.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   6%|▌         | 304M/4.95G [00:20<02:32, 30.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   6%|▌         | 273M/4.55G [00:20<08:51, 8.04MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   6%|▋         | 320M/4.95G [00:20<02:25, 31.9MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 464M/5.00G [00:20<02:05, 36.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   7%|▋         | 336M/4.95G [00:21<02:19, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   7%|▋         | 352M/4.95G [00:21<02:21, 32.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|▋         | 304M/4.55G [00:21<03:56, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   7%|▋         | 368M/4.95G [00:22<02:14, 34.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   7%|▋         | 320M/4.55G [00:22<03:15, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   8%|▊         | 384M/4.95G [00:22<02:16, 33.5MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  11%|█         | 528M/5.00G [00:22<02:06, 35.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   8%|▊         | 400M/4.95G [00:23<02:14, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  11%|█         | 544M/5.00G [00:23<02:02, 36.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|▊         | 352M/4.55G [00:23<02:43, 25.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   8%|▊         | 416M/4.95G [00:23<02:13, 34.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:   9%|▊         | 432M/4.95G [00:23<02:12, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   8%|▊         | 384M/4.55G [00:24<02:24, 28.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:   9%|▉         | 448M/4.95G [00:24<02:11, 34.4MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   9%|▉         | 464M/4.95G [00:24<02:06, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   9%|▉         | 400M/4.55G [00:24<02:26, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  10%|▉         | 480M/4.95G [00:25<02:05, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:   9%|▉         | 416M/4.55G [00:25<02:15, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  10%|█         | 496M/4.95G [00:25<02:03, 36.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|▉         | 432M/4.55G [00:25<02:07, 32.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  10%|█         | 512M/4.95G [00:26<02:04, 35.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  10%|▉         | 448M/4.55G [00:26<02:11, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  11%|█         | 528M/4.95G [00:26<02:02, 36.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  11%|█         | 544M/4.95G [00:27<02:00, 36.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 624M/5.00G [00:27<02:30, 29.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|█         | 480M/4.55G [00:27<01:59, 34.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  11%|█▏        | 560M/4.95G [00:27<02:03, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|█         | 496M/4.55G [00:27<02:06, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  12%|█▏        | 576M/4.95G [00:28<02:17, 31.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  11%|█▏        | 512M/4.55G [00:28<02:00, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 672M/5.00G [00:28<02:19, 30.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  12%|█▏        | 592M/4.95G [00:28<02:18, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  12%|█▏        | 608M/4.95G [00:29<02:16, 31.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  13%|█▎        | 624M/4.95G [00:29<02:10, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  12%|█▏        | 560M/4.55G [00:29<01:59, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  13%|█▎        | 640M/4.95G [00:30<02:07, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  13%|█▎        | 576M/4.55G [00:30<01:57, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  13%|█▎        | 656M/4.95G [00:30<02:10, 32.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  13%|█▎        | 592M/4.55G [00:30<02:15, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  14%|█▎        | 672M/4.95G [00:30<02:07, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  14%|█▍        | 688M/4.95G [00:31<02:00, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 752M/5.00G [00:31<02:28, 28.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|█▎        | 624M/4.55G [00:31<02:01, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  14%|█▍        | 704M/4.95G [00:32<02:14, 31.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|█▍        | 640M/4.55G [00:32<02:00, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  15%|█▍        | 720M/4.95G [00:32<02:11, 32.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  14%|█▍        | 656M/4.55G [00:32<02:04, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  15%|█▍        | 736M/4.95G [00:32<02:06, 33.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  15%|█▍        | 672M/4.55G [00:33<01:56, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  15%|█▌        | 752M/4.95G [00:33<02:03, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  16%|█▌        | 768M/4.95G [00:33<01:59, 35.0MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  16%|█▌        | 784M/4.95G [00:34<01:57, 35.4MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 848M/5.00G [00:34<02:19, 29.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|█▌        | 800M/4.95G [00:34<01:59, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  15%|█▌        | 683M/4.55G [00:35<05:02, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 864M/5.00G [00:35<02:16, 30.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  16%|█▋        | 816M/4.95G [00:35<01:59, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  17%|█▋        | 832M/4.95G [00:35<02:01, 33.8MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 886M/5.00G [00:35<02:04, 32.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  17%|█▋        | 848M/4.95G [00:36<01:59, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  15%|█▌        | 704M/4.55G [00:36<04:00, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  17%|█▋        | 864M/4.95G [00:36<02:01, 33.5MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 893M/5.00G [00:36<03:33, 19.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|█▌        | 720M/4.55G [00:36<02:59, 21.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  18%|█▊        | 880M/4.95G [00:37<01:55, 35.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|█▌        | 736M/4.55G [00:37<02:34, 24.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  18%|█▊        | 896M/4.95G [00:37<01:55, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  18%|█▊        | 912M/4.95G [00:37<01:54, 35.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|█▋        | 743M/4.55G [00:38<03:32, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  19%|█▊        | 928M/4.95G [00:38<01:57, 34.3MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  19%|█▉        | 944M/4.95G [00:38<02:00, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|█▋        | 745M/4.55G [00:39<06:22, 9.93MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 944M/5.00G [00:39<02:45, 24.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  16%|█▋        | 747M/4.55G [00:39<06:20, 9.98MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  19%|█▉        | 960M/4.95G [00:39<01:54, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  17%|█▋        | 752M/4.55G [00:39<05:13, 12.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  20%|█▉        | 976M/4.95G [00:39<01:59, 33.1MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 976M/5.00G [00:40<02:16, 29.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|██        | 992M/4.95G [00:40<01:57, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 992M/5.00G [00:40<02:12, 30.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  20%|██        | 1.01G/4.95G [00:40<01:54, 34.4MB/s][A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  17%|█▋        | 784M/4.55G [00:41<02:50, 22.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  21%|██        | 1.02G/4.95G [00:41<01:53, 34.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  18%|█▊        | 800M/4.55G [00:41<02:30, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  21%|██        | 1.04G/4.95G [00:41<01:55, 34.0MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.04G/5.00G [00:42<02:03, 32.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  21%|██▏       | 1.06G/4.95G [00:42<01:50, 35.2MB/s][A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.06G/5.00G [00:42<01:55, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|██▏       | 1.07G/4.95G [00:42<01:53, 34.2MB/s][A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██▏       | 1.07G/5.00G [00:42<01:50, 35.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|██▏       | 1.09G/4.95G [00:43<01:54, 33.8MB/s][A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.09G/5.00G [00:43<02:01, 32.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  22%|██▏       | 1.10G/4.95G [00:43<01:49, 35.1MB/s][A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.10G/5.00G [00:43<01:57, 33.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|██▎       | 1.12G/4.95G [00:44<01:49, 34.9MB/s][A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.12G/5.00G [00:44<01:57, 33.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|██▎       | 1.14G/4.95G [00:44<01:53, 33.6MB/s][A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.14G/5.00G [00:44<01:56, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  23%|██▎       | 1.15G/4.95G [00:45<01:51, 34.0MB/s][A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  24%|██▎       | 1.17G/4.95G [00:45<01:44, 36.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  20%|██        | 928M/4.55G [00:45<01:53, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  24%|██▍       | 1.18G/4.95G [00:45<01:42, 36.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  21%|██        | 944M/4.55G [00:45<01:52, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  24%|██▍       | 1.20G/4.95G [00:46<01:42, 36.7MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  25%|██▍       | 1.23G/4.95G [00:47<01:40, 37.1MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  25%|██▌       | 1.25G/4.95G [00:47<01:38, 37.4MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.23G/5.00G [00:47<01:46, 35.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  21%|██        | 960M/4.55G [00:47<03:12, 18.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  26%|██▌       | 1.26G/4.95G [00:47<01:40, 36.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  21%|██▏       | 976M/4.55G [00:48<02:48, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  26%|██▌       | 1.28G/4.95G [00:48<01:41, 36.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|██▏       | 992M/4.55G [00:48<02:25, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  26%|██▌       | 1.30G/4.95G [00:48<01:40, 36.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  22%|██▏       | 1.01G/4.55G [00:49<02:14, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  27%|██▋       | 1.31G/4.95G [00:49<01:44, 35.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  23%|██▎       | 1.02G/4.55G [00:49<02:06, 27.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  27%|██▋       | 1.33G/4.95G [00:49<01:43, 35.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|██▋       | 1.34G/4.95G [00:50<01:40, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.33G/5.00G [00:50<01:47, 34.1MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.33G/5.00G [00:50<01:50, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  27%|██▋       | 1.36G/4.95G [00:50<01:46, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|██▊       | 1.38G/4.95G [00:51<01:46, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  28%|██▊       | 1.39G/4.95G [00:51<01:47, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.34G/5.00G [00:51<04:09, 14.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  24%|██▍       | 1.10G/4.55G [00:51<01:42, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.34G/5.00G [00:52<04:16, 14.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.34G/5.00G [00:52<04:23, 13.9MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  28%|██▊       | 1.41G/4.95G [00:52<01:50, 32.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  29%|██▉       | 1.42G/4.95G [00:52<01:47, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  25%|██▍       | 1.14G/4.55G [00:52<01:42, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  29%|██▉       | 1.44G/4.95G [00:53<01:42, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  25%|██▌       | 1.15G/4.55G [00:53<01:44, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  29%|██▉       | 1.46G/4.95G [00:53<01:41, 34.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  26%|██▌       | 1.17G/4.55G [00:53<01:42, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  30%|██▉       | 1.47G/4.95G [00:54<01:44, 33.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.39G/5.00G [00:54<02:20, 25.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  30%|███       | 1.49G/4.95G [00:54<01:39, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  26%|██▋       | 1.20G/4.55G [00:54<01:45, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  30%|███       | 1.50G/4.95G [00:55<01:37, 35.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|███       | 1.52G/4.95G [00:55<01:35, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.42G/5.00G [00:55<02:07, 28.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  31%|███       | 1.54G/4.95G [00:55<01:35, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.44G/5.00G [00:56<02:03, 28.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  27%|██▋       | 1.25G/4.55G [00:56<01:35, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  31%|███▏      | 1.55G/4.95G [00:56<01:45, 32.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|██▊       | 1.26G/4.55G [00:56<01:31, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  32%|███▏      | 1.57G/4.95G [00:56<01:42, 32.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  28%|██▊       | 1.28G/4.55G [00:57<01:30, 36.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  32%|███▏      | 1.58G/4.95G [00:57<01:41, 33.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|██▊       | 1.30G/4.55G [00:57<01:31, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  32%|███▏      | 1.60G/4.95G [00:57<01:42, 32.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  29%|██▉       | 1.31G/4.55G [00:57<01:28, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|███▎      | 1.62G/4.95G [00:58<01:41, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.52G/5.00G [00:58<01:53, 30.5MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.54G/5.00G [00:58<01:49, 31.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  33%|███▎      | 1.63G/4.95G [00:59<02:01, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  30%|██▉       | 1.36G/4.55G [00:59<01:33, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  33%|███▎      | 1.65G/4.95G [00:59<01:55, 28.7MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  31%|███▏      | 1.57G/5.00G [00:59<01:45, 32.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|███▎      | 1.66G/4.95G [01:00<01:43, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  31%|███       | 1.39G/4.55G [01:00<01:32, 34.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.58G/5.00G [01:00<01:46, 32.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  34%|███▍      | 1.68G/4.95G [01:00<01:37, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  34%|███▍      | 1.70G/4.95G [01:01<01:38, 32.9MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  35%|███▍      | 1.71G/4.95G [01:01<01:38, 32.7MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  35%|███▍      | 1.73G/4.95G [01:02<01:40, 32.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  31%|███       | 1.40G/4.55G [01:02<03:51, 13.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.65G/5.00G [01:02<01:34, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  31%|███       | 1.40G/4.55G [01:02<03:47, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  35%|███▌      | 1.74G/4.95G [01:02<01:40, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  36%|███▌      | 1.76G/4.95G [01:03<01:37, 32.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  31%|███       | 1.41G/4.55G [01:03<05:23, 9.69MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  36%|███▌      | 1.78G/4.95G [01:03<01:34, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  31%|███▏      | 1.42G/4.55G [01:03<03:19, 15.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  36%|███▌      | 1.79G/4.95G [01:03<01:29, 35.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  32%|███▏      | 1.44G/4.55G [01:04<02:23, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  34%|███▍      | 1.71G/5.00G [01:04<01:36, 34.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███▋      | 1.81G/4.95G [01:04<01:38, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|███▍      | 1.73G/5.00G [01:04<01:35, 34.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███▋      | 1.82G/4.95G [01:05<01:39, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|███▍      | 1.74G/5.00G [01:05<01:34, 34.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  37%|███▋      | 1.84G/4.95G [01:05<01:34, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  37%|███▋      | 1.86G/4.95G [01:05<01:35, 32.4MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.78G/5.00G [01:06<01:35, 33.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  38%|███▊      | 1.87G/4.95G [01:06<01:33, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  33%|███▎      | 1.52G/4.55G [01:06<01:44, 29.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  38%|███▊      | 1.89G/4.95G [01:06<01:29, 34.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|███▍      | 1.54G/4.55G [01:07<01:40, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  38%|███▊      | 1.90G/4.95G [01:07<01:31, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|███▍      | 1.55G/4.55G [01:07<01:34, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  39%|███▉      | 1.92G/4.95G [01:07<01:30, 33.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  34%|███▍      | 1.57G/4.55G [01:08<01:35, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  39%|███▉      | 1.94G/4.95G [01:08<01:31, 32.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███▍      | 1.58G/4.55G [01:08<01:31, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  39%|███▉      | 1.95G/4.95G [01:08<01:35, 31.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  35%|███▌      | 1.60G/4.55G [01:08<01:30, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  40%|███▉      | 1.97G/4.95G [01:09<01:28, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███▌      | 1.62G/4.55G [01:09<01:30, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  40%|████      | 1.98G/4.95G [01:09<01:29, 33.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  36%|███▌      | 1.63G/4.55G [01:10<01:31, 31.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  40%|████      | 2.00G/4.95G [01:10<01:29, 32.9MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.92G/5.00G [01:10<01:31, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|████      | 2.02G/4.95G [01:10<01:31, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  39%|███▊      | 1.94G/5.00G [01:10<01:28, 34.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|████      | 2.03G/4.95G [01:11<01:28, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.95G/5.00G [01:11<01:26, 35.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  41%|████▏     | 2.05G/4.95G [01:11<01:25, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.97G/5.00G [01:11<01:25, 35.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|████▏     | 2.06G/4.95G [01:12<01:21, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  40%|███▉      | 1.98G/5.00G [01:12<01:30, 33.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|████▏     | 2.08G/4.95G [01:12<01:22, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  40%|████      | 2.00G/5.00G [01:12<01:29, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  42%|████▏     | 2.10G/4.95G [01:13<01:20, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  38%|███▊      | 1.74G/4.55G [01:13<01:18, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  43%|████▎     | 2.11G/4.95G [01:13<01:20, 35.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.03G/5.00G [01:13<01:24, 35.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  43%|████▎     | 2.13G/4.95G [01:13<01:21, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  39%|███▉      | 1.78G/4.55G [01:14<01:15, 36.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  43%|████▎     | 2.14G/4.95G [01:14<01:22, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  39%|███▉      | 1.79G/4.55G [01:14<01:15, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  44%|████▎     | 2.16G/4.95G [01:14<01:20, 34.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  40%|███▉      | 1.81G/4.55G [01:14<01:14, 36.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  44%|████▍     | 2.18G/4.95G [01:15<01:16, 36.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  40%|████      | 1.82G/4.55G [01:15<01:19, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  44%|████▍     | 2.19G/4.95G [01:15<01:13, 37.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  40%|████      | 1.84G/4.55G [01:15<01:17, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  45%|████▍     | 2.21G/4.95G [01:16<01:17, 35.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  41%|████      | 1.86G/4.55G [01:16<01:15, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  45%|████▍     | 2.22G/4.95G [01:16<01:14, 36.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  45%|████▌     | 2.24G/4.95G [01:17<01:14, 36.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.14G/5.00G [01:17<01:31, 31.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|████▌     | 2.26G/4.95G [01:17<01:16, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.16G/5.00G [01:17<01:42, 27.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  46%|████▌     | 2.29G/4.95G [01:18<01:13, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  42%|████▏     | 1.92G/4.55G [01:18<01:20, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  44%|████▎     | 2.18G/5.00G [01:18<01:38, 28.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████▋     | 2.30G/4.95G [01:18<01:13, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.19G/5.00G [01:18<01:31, 30.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████▋     | 2.32G/4.95G [01:19<01:13, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.21G/5.00G [01:19<01:27, 31.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  47%|████▋     | 2.34G/4.95G [01:19<01:11, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.22G/5.00G [01:19<01:22, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████▊     | 2.35G/4.95G [01:20<01:11, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.24G/5.00G [01:20<01:21, 34.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|████▍     | 2.00G/4.55G [01:20<01:14, 34.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  48%|████▊     | 2.37G/4.95G [01:20<01:23, 30.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  44%|████▍     | 2.02G/4.55G [01:21<01:11, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  48%|████▊     | 2.38G/4.95G [01:21<01:20, 31.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  48%|████▊     | 2.40G/4.95G [01:21<01:17, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.29G/5.00G [01:21<01:32, 29.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  49%|████▉     | 2.42G/4.95G [01:22<01:19, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.30G/5.00G [01:22<01:27, 30.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  45%|████▌     | 2.06G/4.55G [01:22<01:14, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  49%|████▉     | 2.43G/4.95G [01:22<01:22, 30.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  46%|████▌     | 2.08G/4.55G [01:23<01:10, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  49%|████▉     | 2.45G/4.95G [01:23<01:22, 30.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|████▉     | 2.46G/4.95G [01:23<01:16, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.35G/5.00G [01:23<01:24, 31.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  50%|█████     | 2.48G/4.95G [01:24<01:14, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.37G/5.00G [01:24<01:25, 30.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  47%|████▋     | 2.13G/4.55G [01:24<01:18, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  50%|█████     | 2.50G/4.95G [01:24<01:19, 30.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  47%|████▋     | 2.14G/4.55G [01:25<01:16, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  51%|█████     | 2.51G/4.95G [01:25<01:21, 29.9MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.42G/5.00G [01:25<01:16, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  51%|█████     | 2.53G/4.95G [01:25<01:21, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  48%|████▊     | 2.18G/4.55G [01:26<01:13, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  51%|█████▏    | 2.54G/4.95G [01:26<01:18, 30.6MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.45G/5.00G [01:26<01:17, 32.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  52%|█████▏    | 2.56G/4.95G [01:26<01:13, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.46G/5.00G [01:27<01:15, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|████▊     | 2.21G/4.55G [01:27<01:12, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  52%|█████▏    | 2.59G/4.95G [01:27<01:11, 32.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|████▉     | 2.22G/4.55G [01:28<01:27, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  53%|█████▎    | 2.61G/4.95G [01:28<01:07, 34.6MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.48G/5.00G [01:28<02:07, 19.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  49%|████▉     | 2.24G/4.55G [01:28<01:21, 28.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  53%|█████▎    | 2.62G/4.95G [01:28<01:09, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  53%|█████▎    | 2.64G/4.95G [01:29<01:08, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.48G/5.00G [01:29<03:47, 11.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  50%|████▉     | 2.27G/4.55G [01:29<01:13, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.50G/5.00G [01:29<02:26, 17.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|█████▎    | 2.66G/4.95G [01:29<01:17, 29.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.51G/5.00G [01:30<01:52, 22.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|█████▍    | 2.67G/4.95G [01:30<01:14, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.53G/5.00G [01:30<01:36, 25.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  54%|█████▍    | 2.69G/4.95G [01:30<01:15, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.54G/5.00G [01:31<01:26, 28.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|█████▍    | 2.70G/4.95G [01:31<01:10, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.56G/5.00G [01:31<01:21, 29.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|█████▍    | 2.72G/4.95G [01:31<01:09, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.58G/5.00G [01:32<01:16, 31.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  55%|█████▌    | 2.74G/4.95G [01:32<01:07, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  56%|█████▌    | 2.75G/4.95G [01:32<01:04, 33.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  52%|█████▏    | 2.38G/4.55G [01:32<01:07, 32.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  56%|█████▌    | 2.77G/4.95G [01:33<01:02, 34.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  53%|█████▎    | 2.40G/4.55G [01:33<01:06, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.62G/5.00G [01:33<01:10, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  56%|█████▌    | 2.78G/4.95G [01:33<01:04, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  57%|█████▋    | 2.80G/4.95G [01:34<01:01, 35.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  53%|█████▎    | 2.43G/4.55G [01:34<01:02, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  57%|█████▋    | 2.82G/4.95G [01:34<01:01, 34.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  54%|█████▍    | 2.45G/4.55G [01:34<01:02, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  57%|█████▋    | 2.83G/4.95G [01:35<01:00, 34.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  54%|█████▍    | 2.46G/4.55G [01:35<01:01, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  58%|█████▊    | 2.85G/4.95G [01:35<00:59, 35.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  55%|█████▍    | 2.48G/4.55G [01:35<01:04, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  58%|█████▊    | 2.86G/4.95G [01:36<01:02, 33.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  58%|█████▊    | 2.88G/4.95G [01:36<00:59, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.72G/5.00G [01:36<01:20, 28.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████▊    | 2.90G/4.95G [01:36<00:57, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████▉    | 2.91G/4.95G [01:37<00:56, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████▉    | 2.93G/4.95G [01:37<00:57, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  59%|█████▉    | 2.94G/4.95G [01:38<00:56, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|█████▉    | 2.96G/4.95G [01:39<01:06, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|██████    | 2.98G/4.95G [01:39<01:03, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  60%|██████    | 2.99G/4.95G [01:39<01:02, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████    | 3.01G/4.95G [01:40<01:01, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  61%|██████    | 3.02G/4.95G [01:41<01:12, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  58%|█████▊    | 2.66G/4.55G [01:41<00:57, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████▉    | 2.67G/4.55G [01:41<00:56, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  61%|██████▏   | 3.04G/4.95G [01:42<01:20, 23.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████▉    | 2.69G/4.55G [01:42<00:55, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  62%|██████▏   | 3.06G/4.95G [01:42<01:12, 26.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  59%|█████▉    | 2.70G/4.55G [01:42<00:53, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  62%|██████▏   | 3.07G/4.95G [01:43<01:06, 28.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  60%|█████▉    | 2.72G/4.55G [01:43<00:51, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.78G/5.00G [01:43<02:20, 15.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  62%|██████▏   | 3.09G/4.95G [01:43<01:03, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.80G/5.00G [01:43<01:56, 18.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  63%|██████▎   | 3.10G/4.95G [01:44<01:00, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  63%|██████▎   | 3.12G/4.95G [01:44<00:56, 32.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  63%|██████▎   | 3.14G/4.95G [01:44<00:55, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.83G/5.00G [01:44<01:31, 23.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  61%|██████    | 2.78G/4.55G [01:45<00:52, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  64%|██████▎   | 3.15G/4.95G [01:45<00:53, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  62%|██████▏   | 2.80G/4.55G [01:45<00:53, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.86G/5.00G [01:45<01:15, 28.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  64%|██████▍   | 3.17G/4.95G [01:45<00:56, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  64%|██████▍   | 3.18G/4.95G [01:46<00:54, 32.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  62%|██████▏   | 2.83G/4.55G [01:46<00:51, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  65%|██████▍   | 3.20G/4.95G [01:46<00:52, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  63%|██████▎   | 2.85G/4.55G [01:47<00:53, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  65%|██████▍   | 3.22G/4.95G [01:47<00:52, 32.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  63%|██████▎   | 2.86G/4.55G [01:47<00:53, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  65%|██████▌   | 3.23G/4.95G [01:47<00:51, 33.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  63%|██████▎   | 2.88G/4.55G [01:47<00:50, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  66%|██████▌   | 3.25G/4.95G [01:48<00:51, 33.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  64%|██████▎   | 2.90G/4.55G [01:48<00:52, 31.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  59%|█████▉    | 2.96G/5.00G [01:48<00:58, 34.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|██████▌   | 3.26G/4.95G [01:49<00:57, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|█████▉    | 2.98G/5.00G [01:49<00:58, 34.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  66%|██████▋   | 3.28G/4.95G [01:49<00:53, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|█████▉    | 2.99G/5.00G [01:49<00:56, 35.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|██████▋   | 3.30G/4.95G [01:49<00:51, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  67%|██████▋   | 3.31G/4.95G [01:50<00:49, 33.0MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|██████    | 3.02G/5.00G [01:50<00:55, 35.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  67%|██████▋   | 3.33G/4.95G [01:50<00:50, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.04G/5.00G [01:50<00:55, 35.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|██████▊   | 3.34G/4.95G [01:51<00:48, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.06G/5.00G [01:51<00:58, 33.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|██████▊   | 3.36G/4.95G [01:51<00:46, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  61%|██████▏   | 3.07G/5.00G [01:51<00:57, 33.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  68%|██████▊   | 3.38G/4.95G [01:52<00:45, 34.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.09G/5.00G [01:52<00:55, 34.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|██████▊   | 3.39G/4.95G [01:52<00:45, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.10G/5.00G [01:52<00:53, 35.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|██████▉   | 3.41G/4.95G [01:53<00:45, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.12G/5.00G [01:53<00:54, 34.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  69%|██████▉   | 3.42G/4.95G [01:53<00:43, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.14G/5.00G [01:53<00:55, 33.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|██████▉   | 3.44G/4.95G [01:54<00:46, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.15G/5.00G [01:54<00:54, 34.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|██████▉   | 3.46G/4.95G [01:54<00:44, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.17G/5.00G [01:54<00:53, 34.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|███████   | 3.47G/4.95G [01:55<00:43, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▎   | 3.18G/5.00G [01:55<00:53, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  70%|███████   | 3.49G/4.95G [01:55<00:43, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.20G/5.00G [01:55<00:56, 31.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|███████   | 3.50G/4.95G [01:56<00:43, 33.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.22G/5.00G [01:56<00:55, 31.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|███████   | 3.52G/4.95G [01:56<00:42, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▍   | 3.23G/5.00G [01:56<00:52, 33.5MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▍   | 3.24G/5.00G [01:56<00:50, 35.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  71%|███████▏  | 3.54G/4.95G [01:57<00:41, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|███████▏  | 3.55G/4.95G [01:57<00:42, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▍   | 3.24G/5.00G [01:57<01:32, 19.1MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▍   | 3.24G/5.00G [01:57<01:31, 19.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  70%|███████   | 3.20G/4.55G [01:57<00:44, 30.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  72%|███████▏  | 3.57G/4.95G [01:58<00:44, 31.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  72%|███████▏  | 3.58G/4.95G [01:58<00:41, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  73%|███████▎  | 3.60G/4.95G [01:59<00:41, 32.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|███████   | 3.23G/4.55G [01:59<00:48, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  73%|███████▎  | 3.62G/4.95G [01:59<00:41, 32.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  71%|███████▏  | 3.25G/4.55G [01:59<00:44, 29.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  73%|███████▎  | 3.63G/4.95G [01:59<00:39, 33.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  72%|███████▏  | 3.26G/4.55G [02:00<00:42, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.30G/5.00G [02:00<01:06, 25.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████▎  | 3.65G/4.95G [02:00<00:45, 28.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.31G/5.00G [02:00<01:01, 27.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████▍  | 3.66G/4.95G [02:01<00:41, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.33G/5.00G [02:01<00:57, 29.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  74%|███████▍  | 3.68G/4.95G [02:01<00:40, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.34G/5.00G [02:01<00:53, 31.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  73%|███████▎  | 3.33G/4.55G [02:02<00:37, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  75%|███████▍  | 3.71G/4.95G [02:02<00:37, 32.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████▎  | 3.34G/4.55G [02:02<00:38, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  75%|███████▌  | 3.73G/4.95G [02:03<00:36, 33.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  74%|███████▍  | 3.36G/4.55G [02:03<00:36, 32.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.39G/5.00G [02:03<00:50, 31.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|███████▌  | 3.74G/4.95G [02:03<00:36, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.41G/5.00G [02:03<00:49, 32.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|███████▌  | 3.76G/4.95G [02:04<00:35, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.42G/5.00G [02:04<00:48, 32.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  76%|███████▋  | 3.78G/4.95G [02:04<00:36, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.44G/5.00G [02:04<00:46, 33.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  75%|███████▌  | 3.42G/4.55G [02:04<00:32, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  77%|███████▋  | 3.79G/4.95G [02:05<00:36, 31.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  77%|███████▋  | 3.81G/4.95G [02:05<00:36, 31.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.47G/5.00G [02:05<00:46, 32.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|███████▌  | 3.46G/4.55G [02:05<00:31, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  77%|███████▋  | 3.82G/4.95G [02:06<00:35, 31.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  76%|███████▋  | 3.47G/4.55G [02:06<00:30, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  78%|███████▊  | 3.84G/4.95G [02:06<00:34, 32.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  77%|███████▋  | 3.49G/4.55G [02:06<00:30, 34.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  78%|███████▊  | 3.86G/4.95G [02:07<00:33, 32.9MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████   | 3.54G/5.00G [02:07<00:40, 35.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  78%|███████▊  | 3.87G/4.95G [02:07<00:32, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████   | 3.55G/5.00G [02:07<00:41, 34.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|███████▊  | 3.89G/4.95G [02:08<00:33, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████▏  | 3.57G/5.00G [02:08<00:41, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|███████▉  | 3.90G/4.95G [02:08<00:31, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.58G/5.00G [02:08<00:41, 34.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  79%|███████▉  | 3.92G/4.95G [02:08<00:30, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  78%|███████▊  | 3.57G/4.55G [02:09<00:28, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  80%|███████▉  | 3.94G/4.95G [02:09<00:29, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|███████▉  | 3.58G/4.55G [02:09<00:27, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  80%|███████▉  | 3.95G/4.95G [02:09<00:27, 36.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  79%|███████▉  | 3.60G/4.55G [02:10<00:26, 36.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  80%|████████  | 3.97G/4.95G [02:10<00:30, 32.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  80%|███████▉  | 3.62G/4.55G [02:10<00:26, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  80%|████████  | 3.98G/4.95G [02:10<00:29, 32.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  80%|███████▉  | 3.63G/4.55G [02:11<00:26, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  81%|████████  | 4.00G/4.95G [02:11<00:28, 33.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  80%|████████  | 3.65G/4.55G [02:11<00:25, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  81%|████████  | 4.02G/4.95G [02:11<00:27, 33.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  81%|████████  | 3.66G/4.55G [02:11<00:24, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  81%|████████▏ | 4.03G/4.95G [02:12<00:26, 34.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  82%|████████▏ | 4.05G/4.95G [02:12<00:25, 36.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  74%|███████▍  | 3.71G/5.00G [02:12<00:38, 33.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  81%|████████▏ | 3.70G/4.55G [02:12<00:24, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  82%|████████▏ | 4.06G/4.95G [02:13<00:24, 35.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|████████▏ | 3.71G/4.55G [02:13<00:24, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  82%|████████▏ | 4.08G/4.95G [02:13<00:23, 36.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|████████▏ | 3.73G/4.55G [02:13<00:24, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  83%|████████▎ | 4.10G/4.95G [02:14<00:24, 34.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  82%|████████▏ | 3.74G/4.55G [02:14<00:26, 30.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  83%|████████▎ | 4.11G/4.95G [02:14<00:24, 34.8MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.79G/5.00G [02:14<00:34, 34.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  83%|████████▎ | 4.13G/4.95G [02:14<00:23, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  84%|████████▎ | 4.14G/4.95G [02:15<00:23, 33.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|████████▎ | 3.78G/4.55G [02:15<00:26, 28.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  76%|███████▋  | 3.82G/5.00G [02:15<00:34, 33.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  83%|████████▎ | 3.79G/4.55G [02:16<00:24, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  84%|████████▍ | 3.81G/4.55G [02:16<00:23, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.84G/5.00G [02:16<00:41, 28.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  84%|████████▍ | 4.16G/4.95G [02:17<00:39, 20.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.86G/5.00G [02:17<00:39, 28.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  84%|████████▍ | 3.84G/4.55G [02:17<00:22, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  84%|████████▍ | 4.18G/4.95G [02:17<00:38, 19.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  85%|████████▍ | 3.86G/4.55G [02:18<00:21, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  85%|████████▍ | 4.19G/4.95G [02:18<00:32, 23.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████▌ | 4.21G/4.95G [02:18<00:29, 25.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.90G/5.00G [02:19<00:43, 25.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  85%|████████▌ | 4.22G/4.95G [02:19<00:28, 25.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.92G/5.00G [02:19<00:37, 28.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  86%|████████▌ | 4.24G/4.95G [02:19<00:26, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  86%|████████▌ | 3.92G/4.55G [02:19<00:19, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  87%|████████▋ | 3.94G/4.55G [02:20<00:18, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  86%|████████▌ | 4.26G/4.95G [02:20<00:26, 26.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  87%|████████▋ | 3.95G/4.55G [02:20<00:17, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  86%|████████▋ | 4.27G/4.95G [02:21<00:24, 28.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|████████▋ | 4.29G/4.95G [02:21<00:21, 30.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|████████▋ | 4.30G/4.95G [02:21<00:20, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  87%|████████▋ | 4.32G/4.95G [02:22<00:19, 32.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|████████▊ | 4.34G/4.95G [02:22<00:18, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.97G/5.00G [02:22<01:04, 15.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  88%|████████▊ | 4.35G/4.95G [02:23<00:17, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.98G/5.00G [02:23<00:53, 18.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|████████▊ | 4.38G/4.95G [02:24<00:15, 37.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  80%|████████  | 4.00G/5.00G [02:24<00:52, 19.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|████████▉ | 4.40G/4.95G [02:24<00:16, 33.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  80%|████████  | 4.02G/5.00G [02:24<00:45, 21.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|████████▉ | 4.08G/4.55G [02:24<00:14, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 4.03G/5.00G [02:25<00:39, 24.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  90%|█████████ | 4.10G/4.55G [02:25<00:14, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  89%|████████▉ | 4.42G/4.95G [02:26<00:27, 19.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|█████████ | 4.13G/4.55G [02:26<00:14, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  90%|████████▉ | 4.43G/4.95G [02:26<00:23, 21.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|█████████ | 4.14G/4.55G [02:26<00:12, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  90%|████████▉ | 4.45G/4.95G [02:27<00:20, 24.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  91%|█████████▏| 4.16G/4.55G [02:27<00:11, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.08G/5.00G [02:27<00:37, 24.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  90%|█████████ | 4.46G/4.95G [02:27<00:18, 26.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.10G/5.00G [02:27<00:32, 27.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  92%|█████████▏| 4.19G/4.55G [02:28<00:10, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  91%|█████████ | 4.48G/4.95G [02:28<00:16, 28.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|█████████ | 4.50G/4.95G [02:28<00:15, 29.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  91%|█████████ | 4.51G/4.95G [02:29<00:13, 32.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  93%|█████████▎| 4.22G/4.55G [02:29<00:09, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.14G/5.00G [02:29<00:28, 29.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  91%|█████████▏| 4.53G/4.95G [02:29<00:13, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.16G/5.00G [02:29<00:26, 31.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|█████████▏| 4.54G/4.95G [02:30<00:12, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  84%|████████▎ | 4.18G/5.00G [02:30<00:25, 31.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  92%|█████████▏| 4.56G/4.95G [02:30<00:12, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  84%|████████▍ | 4.19G/5.00G [02:30<00:24, 32.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  94%|█████████▍| 4.29G/4.55G [02:30<00:07, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  92%|█████████▏| 4.58G/4.95G [02:31<00:12, 30.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  93%|█████████▎| 4.59G/4.95G [02:31<00:11, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  84%|████████▍ | 4.22G/5.00G [02:31<00:23, 32.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  93%|█████████▎| 4.61G/4.95G [02:32<00:10, 32.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  85%|████████▍ | 4.24G/5.00G [02:32<00:24, 31.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  93%|█████████▎| 4.62G/4.95G [02:32<00:10, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  85%|████████▌ | 4.26G/5.00G [02:32<00:22, 33.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  96%|█████████▌| 4.35G/4.55G [02:32<00:05, 34.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  94%|█████████▎| 4.64G/4.95G [02:33<00:09, 33.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|█████████▍| 4.66G/4.95G [02:33<00:08, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.29G/5.00G [02:33<00:21, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  94%|█████████▍| 4.67G/4.95G [02:33<00:07, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.30G/5.00G [02:34<00:20, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  95%|█████████▍| 4.69G/4.95G [02:34<00:07, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  95%|█████████▌| 4.70G/4.95G [02:34<00:07, 34.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████▋| 4.42G/4.55G [02:34<00:04, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  95%|█████████▌| 4.72G/4.95G [02:35<00:06, 34.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  97%|█████████▋| 4.43G/4.55G [02:35<00:03, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  96%|█████████▌| 4.74G/4.95G [02:35<00:06, 33.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  98%|█████████▊| 4.45G/4.55G [02:35<00:03, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  96%|█████████▌| 4.75G/4.95G [02:36<00:06, 32.1MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.38G/5.00G [02:36<00:18, 33.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  96%|█████████▋| 4.77G/4.95G [02:36<00:05, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  99%|█████████▊| 4.48G/4.55G [02:36<00:02, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00003.safetensors:  97%|█████████▋| 4.78G/4.95G [02:37<00:04, 33.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00003-of-00003.safetensors:  99%|█████████▉| 4.50G/4.55G [02:37<00:01, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.42G/5.00G [02:37<00:17, 33.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  97%|█████████▋| 4.80G/4.95G [02:37<00:04, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  89%|████████▊ | 4.43G/5.00G [02:37<00:17, 33.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  97%|█████████▋| 4.82G/4.95G [02:38<00:04, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.45G/5.00G [02:38<00:16, 34.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00003.safetensors:  98%|█████████▊| 4.83G/4.95G [02:38<00:03, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 4.55G/4.55G [02:39<00:00, 28.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00003.safetensors:  98%|█████████▊| 4.85G/4.95G [02:39<00:03, 31.8MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  98%|█████████▊| 4.86G/4.95G [02:39<00:02, 32.8MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  99%|█████████▉| 4.90G/4.95G [02:40<00:01, 31.3MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  99%|█████████▉| 4.91G/4.95G [02:41<00:01, 32.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  90%|█████████ | 4.51G/5.00G [02:41<00:35, 14.0MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  90%|█████████ | 4.51G/5.00G [02:41<00:34, 14.3MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors: 100%|█████████▉| 4.94G/4.95G [02:42<00:00, 31.9MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  90%|█████████ | 4.51G/5.00G [02:42<00:54, 8.96MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  91%|█████████ | 4.53G/5.00G [02:42<00:30, 15.5MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  91%|█████████ | 4.54G/5.00G [02:43<00:20, 22.1MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors: 100%|██████████| 4.95G/4.95G [02:44<00:00, 30.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  92%|█████████▏| 4.58G/5.00G [02:44<00:14, 29.4MB/s]\u001b[A\n",
      "\n",
      "Upload 3 LFS files:  33%|███▎      | 1/3 [02:44<05:29, 164.56s/it]\u001b[A\u001b[A\n",
      "model-00002-of-00003.safetensors:  92%|█████████▏| 4.59G/5.00G [02:44<00:13, 30.8MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  92%|█████████▏| 4.61G/5.00G [02:45<00:12, 31.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  92%|█████████▏| 4.62G/5.00G [02:45<00:11, 32.7MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  93%|█████████▎| 4.64G/5.00G [02:46<00:11, 32.6MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  93%|█████████▎| 4.66G/5.00G [02:46<00:10, 34.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  93%|█████████▎| 4.67G/5.00G [02:47<00:09, 33.0MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  94%|█████████▍| 4.69G/5.00G [02:47<00:09, 33.6MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  94%|█████████▍| 4.70G/5.00G [02:47<00:08, 34.6MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  94%|█████████▍| 4.72G/5.00G [02:48<00:08, 34.0MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  95%|█████████▍| 4.74G/5.00G [02:48<00:07, 33.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  95%|█████████▌| 4.75G/5.00G [02:49<00:07, 33.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  95%|█████████▌| 4.77G/5.00G [02:49<00:06, 34.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  96%|█████████▌| 4.78G/5.00G [02:50<00:06, 32.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  96%|█████████▌| 4.80G/5.00G [02:50<00:06, 32.0MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  96%|█████████▋| 4.82G/5.00G [02:51<00:05, 32.8MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  97%|█████████▋| 4.83G/5.00G [02:51<00:04, 33.6MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  97%|█████████▋| 4.85G/5.00G [02:52<00:04, 34.7MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  97%|█████████▋| 4.86G/5.00G [02:52<00:04, 33.1MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  98%|█████████▊| 4.88G/5.00G [02:53<00:03, 32.9MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  98%|█████████▊| 4.90G/5.00G [02:53<00:03, 32.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  98%|█████████▊| 4.91G/5.00G [02:54<00:02, 33.3MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  99%|█████████▊| 4.93G/5.00G [02:54<00:02, 33.8MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  99%|█████████▉| 4.94G/5.00G [02:55<00:01, 33.4MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  99%|█████████▉| 4.96G/5.00G [02:55<00:01, 34.2MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors: 100%|█████████▉| 4.98G/5.00G [02:56<00:00, 34.7MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors: 100%|██████████| 5.00G/5.00G [02:57<00:00, 28.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Upload 3 LFS files: 100%|██████████| 3/3 [02:57<00:00, 59.18s/it] \u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/bhums/unsloth_alpaca\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model.push_to_hub(\"bhums/unsloth_alpaca\", token = \"hf_####\")\n",
    "tokenizer.push_to_hub(\"bhums/unsloth_alpaca\", token = \"hf_####\")\n",
    "\n",
    "# For saving merged (if applicable):\n",
    "model.push_to_hub_merged(\"bhums/unsloth_alpaca\", tokenizer, save_method=\"merged_16bit\", token = \"hf_####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22df2500-7040-4714-9f60-47fa7879095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.6\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.568 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. Xformers = 0.0.26.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will load unsloth/mistral-7b-v0.3-bnb-4bit as a legacy tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is a famous tall tower in Paris?\\n\\n### Input:\\n\\n\\n### Response:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"unsloth/mistral-7b-v0.3\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# alpaca_prompt = You MUST copy from above!\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"What is a famous tall tower in Paris?\", # instruction\n",
    "        \"\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    ),\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1659b",
   "metadata": {},
   "source": [
    "### Model is now ready to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea091b2-ba80-41e3-a22e-ed6888826766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 14.84 out of 27.35 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:12<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    }
   ],
   "source": [
    "# Save to q4_k_m GGUF\n",
    "if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "if True: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"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\")\n",
    "if True: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q5_k_m\", token = \"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\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_conda_unslot",
   "language": "python",
   "name": "unsloth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
